{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p align=\"center\">\n",
        "  26 de Novembro de 2021\n",
        "</p>\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img height=\"150\" src=\"https://www.ccs.ufscar.br/imagens/ufscar-preto.png\">\n",
        "</p>\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img height=\"150\" src=\"https://site.dc.ufscar.br/static/media/LOGO-DC.295bfc37.svg\">\n",
        "</p>\n",
        "\n",
        "---\n",
        "\n",
        "<h1 align=\"center\">Trabalho de Aprendizado de Máquina 2</h1>\n",
        "\n",
        "\n",
        "<h3 align=\"center\">Profº. Dr. Diego Furtado Silva</h3>\n",
        "\n",
        "<p align=\"justify\"> Esse trabalho tem o intuito de aplicar cinco datasets multirrótulos diferentes em algoritmos multirrótulos e realizar uma avalicação experimental comparativa da robustez dos algoritmos escolhidos. Assim, Classificação multirrótulo (CMR) pode ser definida como a tarefa de associar múltiplos rótulos de classe para um objeto com base nas características que o descrevem. Atualmente existem muitas aplicações importantes para a tarefa, tais como a categorização de textos (associar documentos texto a tópicos) e a classificação semântica de cenas (associar imagens a conceitos).\n",
        " Um dos exemplos é a categorização automática de músicas, onde o objetivo é associar canções a gêneros musicais. Neste problema, temos, por exemplo, que muitas músicas compostas pelo  músico Tom Jobim consiste em uma mistura de dois gêneros: “Jazz” e “Bossa Nova”. Por esta razão, o problema da categorização de músicas representa um problema de classificaçãomultirrótulo (CMR – multi-label classification) \n",
        " </p>\n",
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "  Lucas Machado Cid (769841) <br>\n",
        "  Victória De Martini de Souza (759378) <br>\n",
        "  Vinicius Quaresma da Luz (769836)\n",
        "</p>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "O código abaixo importa as dependências necessárias para a posterior execução do código. Antes de executar, certifique-se de ter instalado as dependências declaradas no arquivo `requirements.txt`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Declaração de PC bom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "pc_bom = os.sysconf('SC_PAGE_SIZE') * os.sysconf('SC_PHYS_PAGES')/(1024.**3) > 11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icL9rPa_IhMa",
        "outputId": "305d3915-ed0f-4151-9bb4-24bd33e46de9"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score, hamming_loss, precision_score, recall_score\n",
        "from skmultilearn.problem_transform import (BinaryRelevance, ClassifierChain,\n",
        "                                            LabelPowerset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As funções abaixo atuam como métodos de conveniência, além de servirem para que o código fique bem modularizado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "0bztLmluIhMt"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_data(fileName, possible_labels, total_attributes, limit_instances=0):\n",
        "\n",
        "  # Abre o arquivo\n",
        "  file = open('datasets/' + fileName)\n",
        "  csvreader = csv.reader(file, delimiter =' ')\n",
        "\n",
        "  data = []\n",
        "\n",
        "  # Coloca o csv lido em um array\n",
        "  # O csv tem uma última coluna vazia, por isso a descartamos no processo\n",
        "  for row in csvreader:\n",
        "    data.append(row[:-1])\n",
        "\n",
        "  X = []\n",
        "  Y = []\n",
        "\n",
        "  # Pega os dados crus e os divide em atributos e rótulos.\n",
        "  iteration_limit = len(data) if limit_instances == 0 else limit_instances\n",
        "  for i in range(iteration_limit):\n",
        "\n",
        "    # Inicializa o array de atributos para cada elemento\n",
        "    lx = []\n",
        "    for j in range(total_attributes):\n",
        "      lx.append(np.nan)\n",
        "\n",
        "    # Trata os valores para se encaixar no modelo de dados aceito pelo sklearn\n",
        "    for j in range(1, len(data[i])):\n",
        "      attribute = int(data[i][j].split(\":\")[0]) - 1\n",
        "      lx[attribute] = float(data[i][j].split(\":\")[1])\n",
        "\n",
        "    X.append(lx)\n",
        "\n",
        "    # Os rótulos obtidos pelo csv estão todos juntos no primeiro atributo, separados por virgula\n",
        "    # Para cada um dos rótulos possíveis (definido em possible_labels), verifica se o elemento contém ou não cada um dos rótulus\n",
        "    # e cria novas colunas na tabela com valores 0 ou 1 que indicam se o elemento tem ou não determinado rótulo\n",
        "    ly = []\n",
        "    for j in range(len(possible_labels)):\n",
        "      ly.append(1 if possible_labels[j] in data[i][0].split(\",\") else 0)\n",
        "    Y.append(ly)\n",
        "\n",
        "  # Para valores ausentes, coloca-se a média dos outros elementos para aquele atributo\n",
        "  imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "  X = imp.fit_transform(X)\n",
        "\n",
        "  return [X, Y]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "PiTP6yB_IhMw"
      },
      "outputs": [],
      "source": [
        "def get_metrics(classifier, X_train, X_test, Y_train, Y_test):\n",
        "    classifier.fit(np.array(X_train), np.array(Y_train))\n",
        "\n",
        "    pred = classifier.predict(X_test)\n",
        "    \n",
        "    accuracy = accuracy_score(Y_test, pred)\n",
        "    hl = hamming_loss(Y_test, pred)\n",
        "    precision = precision_score(Y_test, pred, average='macro', zero_division=0)\n",
        "    recall = recall_score(Y_test, pred, average='macro', zero_division=0)\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'hamming_loss': hl,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "BtqZdcLpIhMy"
      },
      "outputs": [],
      "source": [
        "class RunResult:\n",
        "  algorithm: str\n",
        "  dataset: str\n",
        "  accuracy_score: float\n",
        "  hamming_loss: float\n",
        "  precision: float\n",
        "  recall: float\n",
        "\n",
        "  def __init__(self, algorithm, dataset, accuracy_score, hamming_loss, precision, recall):\n",
        "    self.algorithm = algorithm\n",
        "    self.dataset = dataset\n",
        "    self.accuracy_score = accuracy_score\n",
        "    self.hamming_loss = hamming_loss\n",
        "    self.precision = precision\n",
        "    self.recall = recall\n",
        "  \n",
        "  def __str__(self):\n",
        "    return f'algorithm: {self.algorithm}\\ndataset: {self.dataset}\\naccuracy_score: {self.accuracy_score}\\nhamming_loss: {self.hamming_loss}\\nprecision: {self.precision}\\nrecall: {self.recall}\\n\\n'\n",
        "  \n",
        "\n",
        "results = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Algoritmos utilizados\n",
        "\n",
        "## Binary Relevance\n",
        "O algoritmo Binary Relevance é o caso mais clássico de transformação de rótulos, visto que o algoritmo transforma os k possíveis rótulos de cada exemplo em k classificadores binários. Cada classificador é treinado para dizer se cada um dos exemplos possui, ou não, um rótulo especifico associonado a ele.\n",
        "\n",
        "## Encadeamento de Classificadores (CC)\n",
        "O algoritmo CC tenta resolver o problema de uma possível dependência entres as classes.\n",
        "\n",
        "## Label Powerset\n",
        "\n",
        "O algoritmo Label Powerset transforma um problema multirótulo em um problema multiclasse, sendo efetivo quando o problema tem poucos rótulos, ou poucas combinações entre os rótulos, logo que um número alto de rótulos aumenta muito o número de classes possíveis tornando o problema difícil. \n",
        "\n",
        "Número de classes vai ser equivalente a 2^n· de rótulos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Os classificadores que serão utilizados com cada um dos 3 algoritmos selecionados são armazenados na lista abaixo para uso posterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "r95Hu5NVKkPN"
      },
      "outputs": [],
      "source": [
        "classifiers = [{\"name\": \"Classifier Chain\", \"model\": ClassifierChain(RandomForestClassifier())}, \n",
        "               {\"name\": \"Binary Relevance\", \"model\": BinaryRelevance(RandomForestClassifier())}, \n",
        "               {\"name\": \"Label Powerset\", \"model\": LabelPowerset(RandomForestClassifier())}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "def execute(dataset: str, X_train, X_test, Y_train, Y_test):\n",
        "  for classifier in classifiers:\n",
        "    result = get_metrics(classifier['model'], X_train, X_test, Y_train, Y_test)\n",
        "\n",
        "    results.append(RunResult(dataset, classifier['name'], result['accuracy'], result['hamming_loss'], result['precision'], result['recall']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Emotions\n",
        "\n",
        "Este dataset analisa uma série de propriedades musicais e adiciona rótulos à cada exemplo (em que cada exemplo é uma música) de acordo com os sentimentos que a música transmite. Estas fetures contém dados númericos decimais, no qual 8 delas estão relacionados a propriedados como rítmo, e 64 relacionadas com timbre. Já as labels são strings e podem assumir zero ou mais dos seguintes valores: amazed-suprised, happy-pleased, relaxing-calm, quiet-still, sad-lonely e angry-aggresive.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset emotions\n",
        "possible_labels = [\"amazed-suprised\", \"happy-pleased\", \"relaxing-calm\", \n",
        "                    \"quiet-still\", \"sad-lonely\", \"angry-aggresive\"]\n",
        "total_attributes = 73\n",
        "\n",
        "X_test, Y_test = get_data(\"emotions/emotions_test\", possible_labels, total_attributes)\n",
        "X_train, Y_train = get_data(\"emotions/emotions_train\", possible_labels, total_attributes)\n",
        "\n",
        "execute('emotions', X_train, X_test, Y_train, Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Mediamill\n",
        "Este dataset está relacionado à detecção automatizada de 101 conceitos semânticos em multimídia. As labels possíveis variam de 1 a 101 e representam diferentes conceitos. Apesar das labels serem númericas, elas indexam um conjunto de conceitos semânticos.\n",
        "\n",
        "http://jvgemert.github.io/pub/smeulders-search-iciap2007.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset mediamill\n",
        "possible_labels = []\n",
        "total_attributes = 120\n",
        "\n",
        "for i in range(101):\n",
        "  possible_labels.append(str(i))\n",
        "\n",
        "X_train, Y_train = get_data(\"mediamill/mediamill_train\", possible_labels, total_attributes, limit_instances=500)\n",
        "X_test, Y_test = get_data(\"mediamill/mediamill_test\", possible_labels, total_attributes, limit_instances=100)\n",
        "\n",
        "execute('mediamill', X_train, X_test, Y_train, Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDNHsQOIIhM0"
      },
      "source": [
        "## Dataset Yeast\n",
        "\n",
        "---\n",
        "\n",
        "Este dataset é um conjunto de dados de leveduras(fermentos) que consiste em uma interação entre proteína-proteína, útil para aqueles que estão começando em alguns projetos de bioinformática de leveduras. O dataset contém dados sobre ontologia genética e dados de sequência de gene/proteína/promotor para cada um dos genes de levedura. Os métodos de detecção de interação levaram à descoberta de milhares de interações entre proteínas, e ajudam fomentar a relevância em conjuntos de dados de grandes escala para a biologia atual.\n",
        "\n",
        "<br><br>\n",
        "\n",
        "![levedura.jpg](https://cildata.crbs.ucsd.edu/media/thumbnail_display/50888/50888_thumbnailx512.jpg)\n",
        "![levedura1.jpg](https://cildata.crbs.ucsd.edu/media/thumbnail_display/50893/50893_thumbnailx512.jpg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VondjUCfIhM5",
        "outputId": "e14476a9-1608-4ec2-da97-bab7c52a1a86"
      },
      "outputs": [],
      "source": [
        "# Dataset Yeast\n",
        "possible_labels = []\n",
        "total_attributes = 103\n",
        "\n",
        "for i in range(15):\n",
        "  possible_labels.append(str(i))\n",
        "\n",
        "X_train, Y_train = get_data('yeast/yeast_train', possible_labels, total_attributes)\n",
        "X_test, Y_test = get_data('yeast/yeast_test', possible_labels, total_attributes)\n",
        "\n",
        "execute('yeast', X_train, X_test, Y_train, Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4OihSgGIhM6"
      },
      "source": [
        "# Scene\n",
        "\n",
        "Este dataset contém diversas imagens representadas como matrizes de atributos, cada qual relacionada a um ou mais tipos de paisagens, a saber: praia, pôr do sol, folhas de outono, montanha e urbano.\n",
        "\n",
        "Para cada instância, ocorre um total de 249 features, que compõem uma matriz de atributos que representam a imagem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "JiTCgJI7IhM8",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "possible_labels = ['0', '1', '2', '3', '4', '5']\n",
        "\n",
        "X_test, Y_test = get_data('scene/scene_test', possible_labels, 294)\n",
        "X_train, Y_train = get_data('scene/scene_train', possible_labels, 294)\n",
        "\n",
        "execute('scene', X_train, X_test, Y_train, Y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_jATyGVIhM9"
      },
      "source": [
        "# TMC 2007\n",
        "\n",
        "Este dataset contém uma matriz onde cada linha é um documento relativo à relatórios aeroespaciais escritos em texto livre, e cada coluna é a frequência de determinada palavra de interesse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "nFOJ5n7tIhM-"
      },
      "outputs": [],
      "source": [
        "if pc_bom:\n",
        "    possible_labels = []\n",
        "\n",
        "    for i in range(101):\n",
        "        possible_labels.append(str(i))\n",
        "\n",
        "    X_test, Y_test = get_data('tmc2007/tmc2007_test', possible_labels, 47152, limit_instances=1000)\n",
        "    X_train, Y_train = get_data('tmc2007/tmc2007_train', possible_labels, 47152, limit_instances=5000)\n",
        "\n",
        "\n",
        "    execute('tmc2007', X_train, X_test, Y_train, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "algorithm: emotions\n",
            "dataset: Classifier Chain\n",
            "accuracy_score: 0.30198019801980197\n",
            "hamming_loss: 0.20297029702970298\n",
            "precision: 0.7378285838516994\n",
            "recall: 0.5879570834004224\n",
            "\n",
            "\n",
            "algorithm: emotions\n",
            "dataset: Binary Relevance\n",
            "accuracy_score: 0.28217821782178215\n",
            "hamming_loss: 0.1971947194719472\n",
            "precision: 0.768081827592697\n",
            "recall: 0.5799811641488116\n",
            "\n",
            "\n",
            "algorithm: emotions\n",
            "dataset: Label Powerset\n",
            "accuracy_score: 0.3712871287128713\n",
            "hamming_loss: 0.19636963696369636\n",
            "precision: 0.6869592041933196\n",
            "recall: 0.7193688722201514\n",
            "\n",
            "\n",
            "algorithm: mediamill\n",
            "dataset: Classifier Chain\n",
            "accuracy_score: 0.06\n",
            "hamming_loss: 0.04\n",
            "precision: 0.05308022924627958\n",
            "recall: 0.032411253798190875\n",
            "\n",
            "\n",
            "algorithm: mediamill\n",
            "dataset: Binary Relevance\n",
            "accuracy_score: 0.05\n",
            "hamming_loss: 0.03881188118811881\n",
            "precision: 0.04543741391772706\n",
            "recall: 0.03376080119532691\n",
            "\n",
            "\n",
            "algorithm: mediamill\n",
            "dataset: Label Powerset\n",
            "accuracy_score: 0.02\n",
            "hamming_loss: 0.055544554455445545\n",
            "precision: 0.05959786055657334\n",
            "recall: 0.045584788893635916\n",
            "\n",
            "\n",
            "algorithm: yeast\n",
            "dataset: Classifier Chain\n",
            "accuracy_score: 0.22246455834242093\n",
            "hamming_loss: 0.18262450018175208\n",
            "precision: 0.5611163528133546\n",
            "recall: 0.3147006507575257\n",
            "\n",
            "\n",
            "algorithm: yeast\n",
            "dataset: Binary Relevance\n",
            "accuracy_score: 0.1515812431842966\n",
            "hamming_loss: 0.18298800436205018\n",
            "precision: 0.6537722053787786\n",
            "recall: 0.2872470403810546\n",
            "\n",
            "\n",
            "algorithm: yeast\n",
            "dataset: Label Powerset\n",
            "accuracy_score: 0.2682660850599782\n",
            "hamming_loss: 0.18742275536168665\n",
            "precision: 0.5150534467090572\n",
            "recall: 0.3768383037960041\n",
            "\n",
            "\n",
            "algorithm: scene\n",
            "dataset: Classifier Chain\n",
            "accuracy_score: 0.5493311036789298\n",
            "hamming_loss: 0.09016164994425864\n",
            "precision: 0.888796995084478\n",
            "recall: 0.5715301017280905\n",
            "\n",
            "\n",
            "algorithm: scene\n",
            "dataset: Binary Relevance\n",
            "accuracy_score: 0.5418060200668896\n",
            "hamming_loss: 0.0883500557413601\n",
            "precision: 0.9090063556638972\n",
            "recall: 0.5707186224567337\n",
            "\n",
            "\n",
            "algorithm: scene\n",
            "dataset: Label Powerset\n",
            "accuracy_score: 0.7023411371237458\n",
            "hamming_loss: 0.08862876254180602\n",
            "precision: 0.7769166292220152\n",
            "recall: 0.7258481575192356\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Print the results as a table\n",
        "for result in results:\n",
        "    print(result)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Trabalho1.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "c9a8e7a37363bcf7f7834afbb21e5caff3afdecb748e2a4bad18eed61cb1d104"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('.venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
